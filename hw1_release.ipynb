{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CS 1810 Homework 1**\n",
    "---\n",
    "To account for potential version issues, try the following in your terminal:\n",
    "\n",
    "1. Create a new environment with `python3 -m venv venv`\n",
    "2. Activate that environment with `source venv/bin/activate`\n",
    "3. Make sure the interpreter in the top right corner of your VSCode (or whatever you use to run your code is venv).\n",
    "4. If you get a \"install kernel\" message, press it.\n",
    "5. Run `pip install -r requirements.txt`\n",
    "6. Run the remainder of this notebook.\n",
    "\n",
    "Note that this is not necessary but can help prevent any issues due to package versions.\n",
    "\n",
    "**The following notebook is meant to help you work through Problems 1, 3, and 4 on Homework 1. You are by no means required to use it, nor are you required to fill out/use any of the boilerplate code/functions. You are welcome to implement the functions however you wish.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = np.genfromtxt(\"data/earth_temperature_sampled_train.csv\", delimiter = ',')\n",
    "year_train = train_data[:, 0] / 1000\n",
    "temp_train = train_data[:, 1]\n",
    "test_data = np.genfromtxt(\"data/earth_temperature_sampled_test.csv\", delimiter = ',')\n",
    "year_test = test_data[:, 0] / 1000\n",
    "temp_test = test_data[:, 1]\n",
    "\n",
    "df_train = pd.read_csv(\"data/earth_temperature_sampled_train.csv\")\n",
    "X_train = df_train[\"# Age\"] / 1000\n",
    "y_train = df_train[\" Temperature\"]\n",
    "\n",
    "df_test = pd.read_csv(\"data/earth_temperature_sampled_test.csv\")\n",
    "X_test = df_train[\"# Age\"] / 1000\n",
    "y_test = df_train[\" Temperature\"]\n",
    "\n",
    "print(f\"First 5 X Training (# Age):\\n{X_train.head()}\\n\")\n",
    "print(f\"First 5 y Training (Temperature):\\n{y_train.head()}\")\n",
    "print(f\"  Mean:     {y_train.mean():.2f}\")\n",
    "print(f\"  Median:   {y_train.median():.2f}\")\n",
    "print(f\"  Std Dev:  {y_train.std():.2f}\")\n",
    "print(f\"  Min:      {y_train.min():.2f}\")\n",
    "print(f\"  Max:      {y_train.max():.2f}\")\n",
    "print(f\"  Range:    {y_train.max() - y_train.min():.2f}\")\n",
    "print(f\"  Q1 (25%): {y_train.quantile(0.25):.2f}\")\n",
    "print(f\"  Q3 (75%): {y_train.quantile(0.75):.2f}\")\n",
    "print(f\"  IQR:      {y_train.quantile(0.75) - y_train.quantile(0.25):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nX_train (Age in thousands)\")\n",
    "print(f\"Shape: {X_train.shape}\")\n",
    "print(f\"Type: {X_train.dtype}\")\n",
    "print(f\"  Mean:     {X_train.mean():.2f}\")\n",
    "print(f\"  Median:   {X_train.median():.2f}\")\n",
    "print(f\"  Std Dev:  {X_train.std():.2f}\")\n",
    "print(f\"  Min:      {X_train.min():.2f}\")\n",
    "print(f\"  Max:      {X_train.max():.2f}\")\n",
    "print(f\"  Range:    {X_train.max() - X_train.min():.2f}\")\n",
    "print(f\"  Q1 (25%): {X_train.quantile(0.25):.2f}\")\n",
    "print(f\"  Q3 (75%): {X_train.quantile(0.75):.2f}\")\n",
    "print(f\"  IQR:      {X_train.quantile(0.75) - X_train.quantile(0.25):.2f}\")\n",
    "\n",
    "print(\"\\ny_train (Temperature in K)\")\n",
    "print(f\"Shape: {y_train.shape}\")\n",
    "print(f\"Type: {y_train.dtype}\")\n",
    "print(f\"  Mean:     {y_train.mean():.2f}\")\n",
    "print(f\"  Median:   {y_train.median():.2f}\")\n",
    "print(f\"  Std Dev:  {y_train.std():.2f}\")\n",
    "print(f\"  Min:      {y_train.min():.2f}\")\n",
    "print(f\"  Max:      {y_train.max():.2f}\")\n",
    "print(f\"  Range:    {y_train.max() - y_train.min():.2f}\")\n",
    "print(f\"  Q1 (25%): {y_train.quantile(0.25):.2f}\")\n",
    "print(f\"  Q3 (75%): {y_train.quantile(0.75):.2f}\")\n",
    "print(f\"  IQR:      {y_train.quantile(0.75) - y_train.quantile(0.25):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Subpart 1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn(x_new, k, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Returns predictions for the values in x_test, using KNN predictor with the specified k.\n",
    "\n",
    "    :param x_new: a numpy array of x_values on which to do prediction. Shape is (n,)\n",
    "    :param k: number of nearest neighbors to consider\n",
    "    :param x_train: x coordinates of training dataset\n",
    "    :param y_train: y coordinates of training dataset\n",
    "\n",
    "    :return: if x_new = [x_1, x_2, ...], then return [f(x_1), f(x_2), ...]\n",
    "             where f is the kNN with specified parameters and training set\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute distances, shape is (n, m) where n is the number of test points and m is the number of training points\n",
    "    dists = np.abs(x_train.reshape(1,-1) - x_new.reshape(-1,1))\n",
    "    # Argsort the rows\n",
    "    ix = dists.argsort(axis = 1)\n",
    "    ix = ix[:, :k] # take only the k smallest distances\n",
    "    y = y_train[ix]\n",
    "\n",
    "    # sum each row\n",
    "    return np.mean(y, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functions\n",
    "N = year_train.shape[0]\n",
    "x_array = np.arange(400, 800, 1)\n",
    "plt.plot(x_array, predict_knn(x_array, 1, year_train, temp_train), label = \"$k = 1$\")\n",
    "plt.plot(x_array, predict_knn(x_array, 3, year_train, temp_train), label = \"$k = 3$\")\n",
    "plt.plot(x_array, predict_knn(x_array, N - 1, year_train, temp_train), label = \"$k = N - 1$\")\n",
    "plt.scatter(year_train, temp_train, label = \"training data\", color = \"red\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.xlabel(\"Year BCE (in thousands)\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(400, 900, 100))\n",
    "plt.ylim([-10,2.5])\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "# save figure to img_output directory\n",
    "plt.savefig(\"img_output/p1.1a.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Subpart 1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mse(predictions, true):\n",
    "    \"\"\"\n",
    "    Calculate the MSE for the given model predictions, with respect to the true values\n",
    "\n",
    "    :param predictions: predictions given by the model\n",
    "    :param true: corresponding true values\n",
    "    :return: the mean squared error\n",
    "    \"\"\"\n",
    "    return np.mean((predictions - true) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSEs for different values of k\n",
    "# YOUR CODE HERE\n",
    "for k in [1, 3, N - 1]:\n",
    "    predictions = predict_knn(year_test, k, year_train, temp_train)\n",
    "    mse = model_mse(predictions, temp_test)\n",
    "    print(f\"k = {k}: Test MSE = {mse:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Subpart 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_regressor(x_new, tau, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Run f_tau(x) with parameter tau on every entry of x_new.\n",
    "\n",
    "    :param x_new: a numpy array of x_values on which to do prediction. Shape is (n,)\n",
    "    :param float tau: lengthscale parameter\n",
    "    :param y_train: the x coordinates of the training set\n",
    "    :param y_train: the y coordinates of the training set\n",
    "    :return: if x_new = [x_1, x_2, ...], then return [f(x_1), f(x_2), ...]\n",
    "             where f is calculated wrt to the training data and tau\n",
    "    \"\"\"\n",
    "    dists_squared = (x_new.reshape(-1, 1) - x_train.reshape(1, -1)) ** 2\n",
    "    K = np.exp(-dists_squared / tau)\n",
    "\n",
    "    numerator = np.sum(K * y_train.reshape(1, -1), axis=1)\n",
    "    denominator = np.sum(K, axis=1)\n",
    "\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot functions\n",
    "x_array = np.arange(400, 800 + 1, 1)\n",
    "for tau in [1, 50, 2500]:\n",
    "    plt.plot(x_array, kernel_regressor(x_array, tau, year_train, temp_train), label = f\"$\\\\tau = {tau}$\")\n",
    "plt.scatter(year_train, temp_train, label = \"training data\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(400, 800 + 100, 100))\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.xlabel(\"Year BCE (in thousands)\")\n",
    "plt.ylim([-10,2.5])\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "# save figure to img_output directory\n",
    "plt.savefig(\"img_output/p1.2a.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Subpart 2(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSEs for different values of tau\n",
    "# YOUR CODE HERE\n",
    "for tau in [1, 50, 2500]:\n",
    "    predictions = kernel_regressor(year_test, tau, year_train, temp_train)\n",
    "    mse = model_mse(predictions, temp_test)\n",
    "    print(f\"Tau = {tau}: Test MSE = {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 Subpart 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_kernel(x,mu):\n",
    "  return np.exp(-1/float(5)*np.power(x-mu,2))\n",
    "\n",
    "def f_scale(X, part = \"a\"):\n",
    "  if part == \"a\":\n",
    "    X = X/181 # 181000\n",
    "  elif part == \"b\":\n",
    "    X = X/4e2 # 4e5\n",
    "  elif part == \"c\":\n",
    "    X = X/1.81 # 1810    \n",
    "  elif part == \"d\":\n",
    "    X = X/.181 # 181\n",
    "  return X\n",
    "\n",
    "# TODO: Complete this `make_basis` function according to the above\n",
    "# specifications. The function should return the array `phi(X)`\n",
    "\n",
    "def make_basis(X, part='a'):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    X: input of years (or any variable you want to turn into the appropriate basis) as\n",
    "        ndarray with length `N`.\n",
    "    part: one of `a`, `b`, `c`, `d` depending on the basis function.\n",
    "\n",
    "    Returns:\n",
    "      ndarray `phi(X)` of shape `(N,D)`. For each part the shapes of your\n",
    "      training data `make_basis(years_train)` should be\n",
    "        (a) 57x10, (b) 57x10, (c) 57x10, (d) 57x50.\n",
    "  \"\"\"\n",
    "    \n",
    "  ### DO NOT CHANGE THIS SECTION \n",
    "  ### it is to prevent numerical instability from taking the exponents of\n",
    "  ### the years, as well as break symmetry when dealing with a Fourier basis.\n",
    "  X = f_scale(X, part)\n",
    "  ### end section\n",
    "\n",
    "  N = len(X)\n",
    "  if part == 'a':\n",
    "    D = 10\n",
    "    phi = np.ones((N, D))\n",
    "    for j in range(1, D):\n",
    "      phi[:, j] = np.power(X, j)\n",
    "\n",
    "  elif part == 'b':\n",
    "    D = 10\n",
    "    phi = np.ones((N, D))\n",
    "    for j in range(1, D):\n",
    "      mu_j = (j + 7) / 8.0\n",
    "      phi[:, j] = exp_kernel(X, mu_j)\n",
    "\n",
    "  elif part == 'c':\n",
    "    D = 10\n",
    "    phi = np.ones((N, D))\n",
    "    for j in range(1, D):\n",
    "      phi[:, j] = np.cos(X / j)\n",
    "\n",
    "  elif part == 'd':\n",
    "    D = 50\n",
    "    phi = np.ones((N, D))\n",
    "    for j in range(1, D):\n",
    "      phi[:, j] = np.cos(X / j)\n",
    "\n",
    "  return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now solving the multi-dimensional OLS regression problem. For each $i=1,\\ldots, N$, we have \n",
    "$$ \\hat y_i = \\mathbf{w}^\\top\\mathbf{\\phi}(x_i) = \\sum_{j=1}^D w_j \\phi_j(x_i).  $$\n",
    "\n",
    "We can find the weights that minimize the MSE $\\frac 1N\\| \\mathbf{y} - \\mathbf{\\phi}(\\mathbf{X})\\mathbf{w}\\| $ with the analytic solution described in the textbook at Derivation 2.6.1.\n",
    "$$ \\mathbf{w^*} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to find the regression weights using the Moore-Penrose pseudoinverse.\n",
    "def find_weights(X,y):\n",
    "    w_star = np.dot(np.linalg.pinv(np.dot(X.T, X)), np.dot(X.T, y))\n",
    "    return w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2,2, figsize = (16,10))\n",
    "\n",
    "mse_results = {}\n",
    "\n",
    "for i, part in enumerate(['a', 'b', 'c' ,'d']):\n",
    "  # Plotting the original data\n",
    "  phi_years_train = make_basis(year_train, part)\n",
    "  w = find_weights(phi_years_train, temp_train)\n",
    "\n",
    "  phi_test = make_basis(year_test, part)\n",
    "  y_test_pred = phi_test @ w\n",
    "  mse = model_mse(y_test_pred, temp_test)\n",
    "  mse_results[part] = mse\n",
    "\n",
    "  \n",
    "  ax[i//2, i%2].scatter(year_train, temp_train, label = \"Original Data\")\n",
    "  \n",
    "  xs = np.linspace(year_train.min(), year_train.max(), 1000)\n",
    "  ax[i//2, i%2].set_xlabel(\"Year\")\n",
    "  ax[i//2, i%2].set_ylabel(\"Temperature\")\n",
    "  ax[i//2, i%2].set_title(f\"OLS Basis Regression; Temperature on Years ({part})\")\n",
    "\n",
    "  ax[i//2, i%2].legend()\n",
    "\n",
    "  # TODO: Plot the regression line generated by your model. \n",
    "  # YOUR CODE HERE\n",
    "  pass\n",
    "  ax[i//2, i%2].invert_xaxis()\n",
    "  \n",
    "plt.savefig(\"img_output/p3.1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 Subpart 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSE for each basis\n",
    "# YOUR CODE HERE\n",
    "for part in ['a', 'b', 'c', 'd']:\n",
    "    print(f\"Basis ({part}): Test MSE = {mse_results[part]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 Subpart 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lasso_weights(lam, X, y):\n",
    "    \"\"\"\n",
    "    Fit the weights of a LASSO linear regression through the coordinate descent algorithm.\n",
    "\n",
    "    :param lam: the lambda parameter\n",
    "    :param X: the design matrix with training set features\n",
    "    :param y: the training set labels\n",
    "    :param max_iter: maximum number of iterations\n",
    "    :param tol: convergence tolerance\n",
    "    :return: the fitted weights\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    w = np.ones(D)  # Initialize with ones as specified\n",
    "    tol = 1e-6\n",
    "\n",
    "    for iteration in range(5000):\n",
    "        w_old = w.copy()\n",
    "\n",
    "        for d in range(D):\n",
    "            # Extract the d-th column\n",
    "            x_d = X[:, d]\n",
    "\n",
    "            # Compute residual excluding the contribution of w_d\n",
    "            residual = y - (X @ w - w[d] * x_d)\n",
    "\n",
    "            # Compute rho_d\n",
    "            rho_d = x_d @ residual\n",
    "\n",
    "            # Update w_d\n",
    "            if d == 0:  # Bias term (no regularization)\n",
    "                w[d] = rho_d / (x_d @ x_d)\n",
    "            else:\n",
    "                norm_sq = x_d @ x_d\n",
    "                w[d] = np.sign(rho_d) * max(abs(rho_d) - lam / 2, 0) / norm_sq\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(w - w_old) < tol:\n",
    "            print(f\"   Converged after {iteration + 1} iterations\")\n",
    "            break\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for standardizing inputs to LASSO\n",
    "def preprocess_lasso(X):\n",
    "    X = make_basis(X, part='d')\n",
    "    X[:, 1:] = (X[:, 1:] - X[:, 1:].mean(axis = 0)) / X[:, 1:].std(axis = 0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the weights for both models\n",
    "phi_x_train = preprocess_lasso(year_train)\n",
    "lam1, lam2 = 1, 10\n",
    "w_unreg = find_weights(phi_x_train, temp_train)\n",
    "w1 = find_lasso_weights(lam1, phi_x_train, temp_train)\n",
    "w2 = find_lasso_weights(lam2, phi_x_train, temp_train)\n",
    "\n",
    "# Plot functions\n",
    "x_array = np.arange(400, 800 + 1, 1)\n",
    "phi_x_array = preprocess_lasso(x_array)\n",
    "\n",
    "# TODO: Plot the regression line generated by your model. \n",
    "# YOUR CODE HERE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_array, phi_x_array @ w_unreg, label=\"Unregularized (Basis d)\", linewidth=2)\n",
    "plt.plot(x_array, phi_x_array @ w1, label=f\"LASSO $\\\\lambda={lam1}$\", linewidth=2)\n",
    "plt.plot(x_array, phi_x_array @ w2, label=f\"LASSO $\\\\lambda={lam2}$\", linewidth=2)\n",
    "pass\n",
    "\n",
    "plt.scatter(year_train, temp_train, label = \"training data\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(400, 800 + 100, 100))\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.xlabel(\"Year BCE (in thousands)\")\n",
    "\n",
    "plt.gca().invert_xaxis()\n",
    "# save figure to img_output directory\n",
    "plt.savefig(\"img_output/p4.5.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the MSE for both values of lambda\n",
    "# YOUR CODE HERE\n",
    "pass\n",
    "#phi_test = preprocess_lasso(year_test)\n",
    "\n",
    "mse_unreg = model_mse(phi_test @ w_unreg, temp_test)\n",
    "mse_lam1 = model_mse(phi_test @ w1, temp_test)\n",
    "mse_lam2 = model_mse(phi_test @ w2, temp_test)\n",
    "\n",
    "print(f\"   Unregularized: Test MSE = {mse_unreg:.4f}\")\n",
    "print(f\"   LASSO λ={lam1}:    Test MSE = {mse_lam1:.4f}\")\n",
    "print(f\"   LASSO λ={lam2}:   Test MSE = {mse_lam2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
